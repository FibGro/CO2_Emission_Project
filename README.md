# CO2_Emission_Project Using Azure Databricks and Power BI

![Example screenshot](./unsplash.jpg)

## Table of Contents
* [General Information](#general-information)
* [Dataset Information](#dataset-information)
* [Technologies Used](#technologies-used)
* [End Result](#end-result)
* [Acknowledgements](#Acknowledgements)
<!-- * [License](#license) -->

## General Information
- This process involves ETL (Extract, Transform, Load).
- Implementing the medallion architecture in Data Lake Gen2 (Bronze, Silver, Gold layers).
- Extracting data from multiple sources into the Bronze layer of Data Lake Gen2.
- Cleaning the dataset and ensuring its integrity.
- Transforming the dataset into Delta format.
- Creating a Snowflake data model.
- Loading transformed data into the Silver layer.
- Aggregating the data and loading it into the Gold layer to support analysis.
- Connecting Databricks with Power BI.
- Creating dashboards and reports in Power BI to display insights.

## Dataset Information

The dataset consists : 
- Transaction information for multiple accounts.
- Currency conversion data.
- Code translation information.

## Technologies Used
- Azure databricks
- Data Lake Gen2 
- Power BI 

## End Result 

- Please refer to the GitHub for Pyspark coding
- Since I use PowerBI Free account, I could not share the result 

